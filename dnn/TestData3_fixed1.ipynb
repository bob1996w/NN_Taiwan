{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tensorflow.contrib.layers import fully_connected, batch_norm\n",
    "import math\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./DL_final_project/DL_Taiwan_data/sinica/201701_Taiwan.csv')\n",
    "#把201701_Taiwan.csv的header的' lat',' lon'改成'lat','lon' (多了空格)\n",
    "train_for_taiwan = False # filter out non-Taiwan\n",
    "#len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[['lat', 'lon']]\n",
    "#df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#need_rows = 100000\n",
    "## pd.options.display.max_rows=1000\n",
    "#dfs = df.head(need_rows)\n",
    "#df.head(need_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ax1 = dfs.plot.scatter(x='lon', y='lat', s=5)\n",
    "#plt.show(ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df2 = df[['Date','Time']].head(10)\n",
    "#df2 = df2.assign(Timestamp = pd.to_datetime(df2['Date']+' '+df2['Time']))\n",
    "#df2 = df2.assign(Hour = df2['Timestamp'].dt.hour)\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_for_taiwan:\n",
    "    df = df[(df['lat']>= 22 )& (df['lat'] <= 25)&(df['lon']>=120)&(df['lon']<=122)]\n",
    "df = df.assign(Timestamp = pd.to_datetime(df['Date']+' '+df['Time']))\n",
    "df = df.assign(Hour = df['Timestamp'].dt.hour)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X = df[['Hour','PM10','PM1','Temperature','Humidity','lon','lat']]\n",
    "#df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfa_X = df_X.values\n",
    "#dfa_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_Y = df[['PM2.5']]\n",
    "dfa_Y = df_Y.values\n",
    "#dfa_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_logdir = \"tf_logs\"\n",
    "batch_log_step = 50\n",
    "early_stopping_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dnn(X_1, y_1, X_2, y_2, X_3, y_3, X_w):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # logs\n",
    "    start_time = datetime.now()\n",
    "    now = start_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    logdir = \"./{}/run-{}\".format(root_logdir, now)\n",
    "    \n",
    "    # dnn graph defs\n",
    "    n_input = 7\n",
    "    n_epochs = 100\n",
    "    n_hidden = [100,100,10]\n",
    "    act_fn = tf.nn.sigmoid\n",
    "    learning_rate = 0.001\n",
    "    batch_normalization = False\n",
    "    batch_size = 10000\n",
    "    #batch_size = 1000 #小範圍測試用\n",
    "    mult_bias = 1000\n",
    "\n",
    "    # I/O\n",
    "    with tf.name_scope(\"Input\"):\n",
    "        X = tf.placeholder(tf.float32, [None, n_input], name=\"X\")\n",
    "        is_training = tf.placeholder(tf.bool, shape=(), name=\"is_training\")\n",
    "    with tf.name_scope(\"Output\"):\n",
    "        y = tf.placeholder(tf.float32, [None, 1], name=\"y\")\n",
    "        y_biased = y/mult_bias\n",
    "    \n",
    "    # batch norm \n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    with tf.name_scope(\"BatchNormArgs\"):\n",
    "        bn_params = {\n",
    "            'is_training': is_training,\n",
    "            'decay': 0.99,\n",
    "            'updates_collections': None,\n",
    "            'scale': True\n",
    "        }\n",
    "    \n",
    "    # DNN\n",
    "    with tf.name_scope(\"DNN\"):\n",
    "        with tf.contrib.framework.arg_scope(\n",
    "                [fully_connected],\n",
    "                weights_initializer = he_init,\n",
    "                normalizer_fn = batch_norm if batch_normalization else None,\n",
    "                normalizer_params = bn_params if batch_normalization else None\n",
    "                ):\n",
    "            h1=fully_connected(X ,n_hidden[0],activation_fn=act_fn,scope=\"h1\")\n",
    "            h2=fully_connected(h1,n_hidden[1],activation_fn=act_fn,scope=\"h2\")\n",
    "            h3=fully_connected(h2,n_hidden[2],activation_fn=act_fn,scope=\"h3\")\n",
    "            logits=fully_connected(h3, 1, activation_fn=act_fn,scope=\"out\")\n",
    "    \n",
    "    with tf.name_scope(\"Cost\"):\n",
    "        #cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y), name=\"cost\")\n",
    "        cost = tf.losses.mean_squared_error(logits, y_biased)\n",
    "    with tf.name_scope(\"AdamOptimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "        minimizer = optimizer.minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.name_scope(\"ModelSaver\"):\n",
    "        saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.name_scope(\"Predict\"):\n",
    "        predict = logits * mult_bias\n",
    "        \n",
    "    with tf.name_scope(\"Error\"):\n",
    "        ave_of_batch_y = tf.reduce_mean(y_biased)\n",
    "        error = tf.abs(logits - y_biased)/ave_of_batch_y\n",
    "        relative_err = tf.reduce_mean(error)\n",
    "    \n",
    "    with tf.name_scope(\"Summaries-Train\"):\n",
    "        cost_summary = tf.summary.scalar('cost_function',cost)\n",
    "        error_summary = tf.summary.scalar('relative_err',relative_err)\n",
    "    with tf.name_scope(\"Summaries-Validation\"):\n",
    "        v_cost_summary = tf.summary.scalar('v_cost_function',cost)\n",
    "        v_error_summary = tf.summary.scalar('v_relative_err',relative_err)\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        total_batch = len(X_1)//batch_size\n",
    "        #total_batch = validation_idx_start//batch_size\n",
    "        print(\"Total batch:\",total_batch)\n",
    "        #X_va, y_va = dfa_X[validation_idx_start:test_idx_start], dfa_Y[validation_idx_start:test_idx_start]\n",
    "        X_va = X_2\n",
    "        y_va = y_2\n",
    "        X_test = X_3\n",
    "        y_test = y_3\n",
    "        \n",
    "        best_va_err_triggered = False\n",
    "        best_va_err = 0\n",
    "        early_stopping_triggered = False\n",
    "        stopping_epoch = 0\n",
    "        step = 0\n",
    "        save_path = \"\"\n",
    "        best_save_path = \"\"\n",
    "        \n",
    "        perm = np.arange(len(X_1))\n",
    "        np.random.shuffle(perm)\n",
    "        X_t = X_1[perm]\n",
    "        y_t = y_1[perm]\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            for batch in range(total_batch):\n",
    "                X_ba = X_t[batch*batch_size: (batch+1)*batch_size]\n",
    "                y_ba = y_t[batch*batch_size: (batch+1)*batch_size]\n",
    "                _, c = sess.run([minimizer, cost], feed_dict = {is_training: True, X:X_ba, y:y_ba})\n",
    "                \n",
    "                if batch % batch_log_step == 0:\n",
    "                    print(\"Epoch %4d batch %5d\"%(epoch,batch))\n",
    "                    cost_summary_str = cost_summary.eval(feed_dict={is_training:False, X:X_ba, y:y_ba})\n",
    "                    step = epoch * total_batch + batch\n",
    "                    file_writer.add_summary(cost_summary_str, step)\n",
    "                    error_summary_str = error_summary.eval(feed_dict={is_training:False, X:X_ba, y:y_ba})\n",
    "                    file_writer.add_summary(error_summary_str, step)\n",
    "            \n",
    "            save_path = saver.save(sess, \"./checkpoint/model_\"+now+\".ckpt\")\n",
    "            va_err, va_cost = sess.run([relative_err, cost], feed_dict={is_training:False, X:X_va, y:y_va})\n",
    "            va_l = sess.run(predict, feed_dict={is_training:False, X:X_va, y:y_va})\n",
    "            rnd_result_idx = random.randint(0, len(X_va)-1)\n",
    "            \n",
    "            print(va_l[rnd_result_idx], y_va[rnd_result_idx]) # print 1st prediction result\n",
    "            v_error_summary_str = v_error_summary.eval(feed_dict={is_training:False, X:X_va, y:y_va})\n",
    "            file_writer.add_summary(v_error_summary_str, step)\n",
    "            v_cost_summary_str = v_cost_summary.eval(feed_dict={is_training:False, X:X_va, y:y_va})\n",
    "            file_writer.add_summary(v_cost_summary_str, step)\n",
    "            print(\"Epoch %4d val.cost %3.6f val.err %3.2f%%\"%(epoch,va_cost,va_err*100),end=\" \")\n",
    "            \n",
    "            if best_va_err_triggered:\n",
    "                if va_err < best_va_err:\n",
    "                    print(\"best\")\n",
    "                    stopping_epoch = 0\n",
    "                    best_va_err = va_err\n",
    "                    \n",
    "                    best_save_path = saver.save(sess, \"./best_model/model_\"+now)\n",
    "                else:\n",
    "                    stopping_epoch += 1\n",
    "                    print(\"stopping %3d\"%stopping_epoch)\n",
    "                if stopping_epoch >= early_stopping_epochs:\n",
    "                    early_stopping_triggered = True\n",
    "                    print(\"Early stopping triggered: Step: %10d, val.err %3.2f%%\"%(step, va_err*100))\n",
    "            else:\n",
    "                best_va_err = va_err\n",
    "                best_va_err_triggered = True\n",
    "                print(\"best\")\n",
    "                best_save_path = saver.save(sess, \"./best_model/model_\"+now)\n",
    "            \n",
    "            if early_stopping_triggered:\n",
    "                break\n",
    "        \n",
    "        finish_time = datetime.now()\n",
    "        print(\"best model saved to:\", best_save_path)\n",
    "        file_writer.close()\n",
    "        elapse_time = finish_time - start_time\n",
    "        total_seconds = elapse_time.total_seconds()\n",
    "        print(\"Total time:\", total_seconds)\n",
    "        \n",
    "        #X_test = dfa_X[test_idx_start:idx_end]\n",
    "        #y_test = dfa_Y[test_idx_start:idx_end]\n",
    "        saver.restore(sess, \"./best_model/model_\"+now)\n",
    "        best_err = relative_err.eval({is_training: False, X: X_test, y: y_test})\n",
    "        print(\"Test Err: %3.2f%%\"%(best_err*100))\n",
    "        \n",
    "        \n",
    "        print(\"Predicting...\")\n",
    "        predict_values = sess.run(predict, feed_dict={is_training: False, X: X_w})\n",
    "        print(\"Predict End\")\n",
    "        return predict_values\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df2: validation\n",
    "# df3: test\n",
    "df2 = pd.read_csv('./DL_final_project/DL_Taiwan_data/sinica/201702_Taiwan.csv')\n",
    "df3 = pd.read_csv('./DL_final_project/DL_Taiwan_data/sinica/201702_Taiwan.csv')\n",
    "test_idx_start = math.floor(len(df2)*0.5)\n",
    "df2 = df2[:test_idx_start]\n",
    "df3 = df3[test_idx_start:]\n",
    "if train_for_taiwan:\n",
    "    df2 = df2[(df2['lat']>= 22 )& (df2['lat'] <= 25)&(df2['lon']>=120)&(df2['lon']<=122)]\n",
    "df2 = df2.assign(Timestamp = pd.to_datetime(df2['Date']+' '+df2['Time']))\n",
    "df3 = df3.assign(Timestamp = pd.to_datetime(df3['Date']+' '+df3['Time']))\n",
    "df2 = df2.assign(Hour = df2['Timestamp'].dt.hour)\n",
    "df3 = df3.assign(Hour = df3['Timestamp'].dt.hour)\n",
    "df2_X = df2[['Hour','PM10','PM1','Temperature','Humidity','lon','lat']]\n",
    "df2_y = df2[['PM2.5']]\n",
    "df3_X = df3[['Hour','PM10','PM1','Temperature','Humidity','lon','lat']]\n",
    "df3_y = df3[['PM2.5']]\n",
    "df2a_X = df2_X.values\n",
    "df2a_y = df2_y.values\n",
    "df3a_X = df3_X.values\n",
    "df3a_y = df3_y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dnn(dfa_X, dfa_Y, df2a_vX, df2a_vy, df3a_tX, df3a_ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df[(df['lat']>= 22 )& (df['lat'] <= 25)&(df['lon']>=120)&(df['lon']<=122)&(df['PM2.5']>700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write predict to file\n",
    "dw = pd.read_csv('./DL_final_project/DL_Taiwan_data/sinica/201703_Taiwan.csv')\n",
    "dfw = dw.assign(Timestamp = pd.to_datetime(dw['Date']+' '+dw['Time']))\n",
    "dfw = dfw.assign(Hour = dfw['Timestamp'].dt.hour)\n",
    "dfw_X = dfw[['Hour','PM10','PM1','Temperature','Humidity','lon','lat']]\n",
    "dfwa_X = dfw_X.values\n",
    "#dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batch: 493\n",
      "Epoch    0 batch     0\n",
      "Epoch    0 batch    50\n",
      "Epoch    0 batch   100\n",
      "Epoch    0 batch   150\n",
      "Epoch    0 batch   200\n",
      "Epoch    0 batch   250\n",
      "Epoch    0 batch   300\n",
      "Epoch    0 batch   350\n",
      "Epoch    0 batch   400\n",
      "Epoch    0 batch   450\n",
      "[ 190.51985168] [30]\n",
      "Epoch    0 val.cost 0.023514 val.err 390.06% best\n",
      "Epoch    1 batch     0\n",
      "Epoch    1 batch    50\n",
      "Epoch    1 batch   100\n",
      "Epoch    1 batch   150\n",
      "Epoch    1 batch   200\n",
      "Epoch    1 batch   250\n",
      "Epoch    1 batch   300\n",
      "Epoch    1 batch   350\n",
      "Epoch    1 batch   400\n",
      "Epoch    1 batch   450\n",
      "[ 93.46316528] [41]\n",
      "Epoch    1 val.cost 0.003511 val.err 141.46% best\n",
      "Epoch    2 batch     0\n",
      "Epoch    2 batch    50\n",
      "Epoch    2 batch   100\n",
      "Epoch    2 batch   150\n",
      "Epoch    2 batch   200\n",
      "Epoch    2 batch   250\n",
      "Epoch    2 batch   300\n",
      "Epoch    2 batch   350\n",
      "Epoch    2 batch   400\n",
      "Epoch    2 batch   450\n",
      "[ 67.28721619] [42]\n",
      "Epoch    2 val.cost 0.001339 val.err 78.05% best\n",
      "Epoch    3 batch     0\n",
      "Epoch    3 batch    50\n",
      "Epoch    3 batch   100\n",
      "Epoch    3 batch   150\n",
      "Epoch    3 batch   200\n",
      "Epoch    3 batch   250\n",
      "Epoch    3 batch   300\n",
      "Epoch    3 batch   350\n",
      "Epoch    3 batch   400\n",
      "Epoch    3 batch   450\n",
      "[ 55.33660507] [13]\n",
      "Epoch    3 val.cost 0.000804 val.err 54.20% best\n",
      "Epoch    4 batch     0\n",
      "Epoch    4 batch    50\n",
      "Epoch    4 batch   100\n",
      "Epoch    4 batch   150\n",
      "Epoch    4 batch   200\n",
      "Epoch    4 batch   250\n",
      "Epoch    4 batch   300\n",
      "Epoch    4 batch   350\n",
      "Epoch    4 batch   400\n",
      "Epoch    4 batch   450\n",
      "[ 48.58877563] [20]\n",
      "Epoch    4 val.cost 0.000628 val.err 45.18% best\n",
      "Epoch    5 batch     0\n",
      "Epoch    5 batch    50\n",
      "Epoch    5 batch   100\n",
      "Epoch    5 batch   150\n",
      "Epoch    5 batch   200\n",
      "Epoch    5 batch   250\n",
      "Epoch    5 batch   300\n",
      "Epoch    5 batch   350\n",
      "Epoch    5 batch   400\n",
      "Epoch    5 batch   450\n",
      "[ 44.48669434] [52]\n",
      "Epoch    5 val.cost 0.000566 val.err 41.94% best\n",
      "Epoch    6 batch     0\n",
      "Epoch    6 batch    50\n",
      "Epoch    6 batch   100\n",
      "Epoch    6 batch   150\n",
      "Epoch    6 batch   200\n",
      "Epoch    6 batch   250\n",
      "Epoch    6 batch   300\n",
      "Epoch    6 batch   350\n",
      "Epoch    6 batch   400\n",
      "Epoch    6 batch   450\n",
      "[ 41.98075867] [45]\n",
      "Epoch    6 val.cost 0.000544 val.err 40.88% best\n",
      "Epoch    7 batch     0\n",
      "Epoch    7 batch    50\n",
      "Epoch    7 batch   100\n",
      "Epoch    7 batch   150\n",
      "Epoch    7 batch   200\n",
      "Epoch    7 batch   250\n",
      "Epoch    7 batch   300\n",
      "Epoch    7 batch   350\n",
      "Epoch    7 batch   400\n",
      "Epoch    7 batch   450\n",
      "[ 40.52652359] [50]\n",
      "Epoch    7 val.cost 0.000537 val.err 40.60% best\n",
      "Epoch    8 batch     0\n",
      "Epoch    8 batch    50\n",
      "Epoch    8 batch   100\n",
      "Epoch    8 batch   150\n",
      "Epoch    8 batch   200\n",
      "Epoch    8 batch   250\n",
      "Epoch    8 batch   300\n",
      "Epoch    8 batch   350\n",
      "Epoch    8 batch   400\n",
      "Epoch    8 batch   450\n",
      "[ 39.75993729] [7]\n",
      "Epoch    8 val.cost 0.000535 val.err 40.55% best\n",
      "Epoch    9 batch     0\n",
      "Epoch    9 batch    50\n",
      "Epoch    9 batch   100\n",
      "Epoch    9 batch   150\n",
      "Epoch    9 batch   200\n",
      "Epoch    9 batch   250\n",
      "Epoch    9 batch   300\n",
      "Epoch    9 batch   350\n",
      "Epoch    9 batch   400\n",
      "Epoch    9 batch   450\n",
      "[ 39.42199326] [39]\n",
      "Epoch    9 val.cost 0.000535 val.err 40.53% best\n",
      "Epoch   10 batch     0\n",
      "Epoch   10 batch    50\n",
      "Epoch   10 batch   100\n",
      "Epoch   10 batch   150\n",
      "Epoch   10 batch   200\n",
      "Epoch   10 batch   250\n",
      "Epoch   10 batch   300\n",
      "Epoch   10 batch   350\n",
      "Epoch   10 batch   400\n",
      "Epoch   10 batch   450\n",
      "[ 39.30763245] [30]\n",
      "Epoch   10 val.cost 0.000534 val.err 40.49% best\n",
      "Epoch   11 batch     0\n",
      "Epoch   11 batch    50\n",
      "Epoch   11 batch   100\n",
      "Epoch   11 batch   150\n",
      "Epoch   11 batch   200\n",
      "Epoch   11 batch   250\n",
      "Epoch   11 batch   300\n",
      "Epoch   11 batch   350\n",
      "Epoch   11 batch   400\n",
      "Epoch   11 batch   450\n",
      "[ 41.2231636] [41]\n",
      "Epoch   11 val.cost 0.000319 val.err 24.50% best\n",
      "Epoch   12 batch     0\n",
      "Epoch   12 batch    50\n",
      "Epoch   12 batch   100\n",
      "Epoch   12 batch   150\n",
      "Epoch   12 batch   200\n",
      "Epoch   12 batch   250\n",
      "Epoch   12 batch   300\n",
      "Epoch   12 batch   350\n",
      "Epoch   12 batch   400\n",
      "Epoch   12 batch   450\n",
      "[ 30.16931725] [24]\n",
      "Epoch   12 val.cost 0.000270 val.err 19.69% best\n",
      "Epoch   13 batch     0\n",
      "Epoch   13 batch    50\n",
      "Epoch   13 batch   100\n",
      "Epoch   13 batch   150\n",
      "Epoch   13 batch   200\n",
      "Epoch   13 batch   250\n",
      "Epoch   13 batch   300\n",
      "Epoch   13 batch   350\n",
      "Epoch   13 batch   400\n",
      "Epoch   13 batch   450\n",
      "[ 33.69242096] [33]\n",
      "Epoch   13 val.cost 0.000224 val.err 17.62% best\n",
      "Epoch   14 batch     0\n",
      "Epoch   14 batch    50\n",
      "Epoch   14 batch   100\n",
      "Epoch   14 batch   150\n",
      "Epoch   14 batch   200\n",
      "Epoch   14 batch   250\n",
      "Epoch   14 batch   300\n",
      "Epoch   14 batch   350\n",
      "Epoch   14 batch   400\n",
      "Epoch   14 batch   450\n",
      "[ 55.70892715] [58]\n",
      "Epoch   14 val.cost 0.000217 val.err 16.94% best\n",
      "Epoch   15 batch     0\n",
      "Epoch   15 batch    50\n",
      "Epoch   15 batch   100\n",
      "Epoch   15 batch   150\n",
      "Epoch   15 batch   200\n",
      "Epoch   15 batch   250\n",
      "Epoch   15 batch   300\n",
      "Epoch   15 batch   350\n",
      "Epoch   15 batch   400\n",
      "Epoch   15 batch   450\n",
      "[ 45.74066162] [49]\n",
      "Epoch   15 val.cost 0.000213 val.err 16.54% best\n",
      "Epoch   16 batch     0\n",
      "Epoch   16 batch    50\n",
      "Epoch   16 batch   100\n",
      "Epoch   16 batch   150\n",
      "Epoch   16 batch   200\n",
      "Epoch   16 batch   250\n",
      "Epoch   16 batch   300\n",
      "Epoch   16 batch   350\n",
      "Epoch   16 batch   400\n",
      "Epoch   16 batch   450\n",
      "[ 52.353302] [53]\n",
      "Epoch   16 val.cost 0.000213 val.err 16.25% best\n",
      "Epoch   17 batch     0\n",
      "Epoch   17 batch    50\n",
      "Epoch   17 batch   100\n",
      "Epoch   17 batch   150\n",
      "Epoch   17 batch   200\n",
      "Epoch   17 batch   250\n",
      "Epoch   17 batch   300\n",
      "Epoch   17 batch   350\n",
      "Epoch   17 batch   400\n",
      "Epoch   17 batch   450\n",
      "[ 31.09203911] [31]\n",
      "Epoch   17 val.cost 0.000211 val.err 16.06% best\n",
      "Epoch   18 batch     0\n",
      "Epoch   18 batch    50\n",
      "Epoch   18 batch   100\n",
      "Epoch   18 batch   150\n",
      "Epoch   18 batch   200\n",
      "Epoch   18 batch   250\n",
      "Epoch   18 batch   300\n",
      "Epoch   18 batch   350\n",
      "Epoch   18 batch   400\n",
      "Epoch   18 batch   450\n",
      "[ 36.50380325] [36]\n",
      "Epoch   18 val.cost 0.000211 val.err 15.90% best\n",
      "Epoch   19 batch     0\n",
      "Epoch   19 batch    50\n",
      "Epoch   19 batch   100\n",
      "Epoch   19 batch   150\n",
      "Epoch   19 batch   200\n",
      "Epoch   19 batch   250\n",
      "Epoch   19 batch   300\n",
      "Epoch   19 batch   350\n",
      "Epoch   19 batch   400\n",
      "Epoch   19 batch   450\n",
      "[ 24.11421967] [4]\n",
      "Epoch   19 val.cost 0.000210 val.err 15.77% best\n",
      "Epoch   20 batch     0\n",
      "Epoch   20 batch    50\n",
      "Epoch   20 batch   100\n",
      "Epoch   20 batch   150\n",
      "Epoch   20 batch   200\n",
      "Epoch   20 batch   250\n",
      "Epoch   20 batch   300\n",
      "Epoch   20 batch   350\n",
      "Epoch   20 batch   400\n",
      "Epoch   20 batch   450\n",
      "[ 29.71723747] [70]\n",
      "Epoch   20 val.cost 0.000206 val.err 15.51% best\n",
      "Epoch   21 batch     0\n",
      "Epoch   21 batch    50\n",
      "Epoch   21 batch   100\n",
      "Epoch   21 batch   150\n",
      "Epoch   21 batch   200\n",
      "Epoch   21 batch   250\n",
      "Epoch   21 batch   300\n",
      "Epoch   21 batch   350\n",
      "Epoch   21 batch   400\n",
      "Epoch   21 batch   450\n",
      "[ 18.7841835] [6]\n",
      "Epoch   21 val.cost 0.000191 val.err 14.05% best\n",
      "Epoch   22 batch     0\n",
      "Epoch   22 batch    50\n",
      "Epoch   22 batch   100\n",
      "Epoch   22 batch   150\n",
      "Epoch   22 batch   200\n",
      "Epoch   22 batch   250\n",
      "Epoch   22 batch   300\n",
      "Epoch   22 batch   350\n",
      "Epoch   22 batch   400\n",
      "Epoch   22 batch   450\n",
      "[ 38.62063217] [40]\n",
      "Epoch   22 val.cost 0.000184 val.err 13.16% best\n",
      "Epoch   23 batch     0\n",
      "Epoch   23 batch    50\n",
      "Epoch   23 batch   100\n",
      "Epoch   23 batch   150\n",
      "Epoch   23 batch   200\n",
      "Epoch   23 batch   250\n",
      "Epoch   23 batch   300\n",
      "Epoch   23 batch   350\n",
      "Epoch   23 batch   400\n",
      "Epoch   23 batch   450\n",
      "[ 32.77719879] [53]\n",
      "Epoch   23 val.cost 0.000180 val.err 12.71% best\n",
      "Epoch   24 batch     0\n",
      "Epoch   24 batch    50\n",
      "Epoch   24 batch   100\n",
      "Epoch   24 batch   150\n",
      "Epoch   24 batch   200\n",
      "Epoch   24 batch   250\n",
      "Epoch   24 batch   300\n",
      "Epoch   24 batch   350\n",
      "Epoch   24 batch   400\n",
      "Epoch   24 batch   450\n",
      "[ 59.77604294] [59]\n",
      "Epoch   24 val.cost 0.000179 val.err 12.43% best\n",
      "Epoch   25 batch     0\n",
      "Epoch   25 batch    50\n",
      "Epoch   25 batch   100\n",
      "Epoch   25 batch   150\n",
      "Epoch   25 batch   200\n",
      "Epoch   25 batch   250\n",
      "Epoch   25 batch   300\n",
      "Epoch   25 batch   350\n",
      "Epoch   25 batch   400\n",
      "Epoch   25 batch   450\n",
      "[ 13.5986557] [15]\n",
      "Epoch   25 val.cost 0.000178 val.err 12.26% best\n",
      "Epoch   26 batch     0\n",
      "Epoch   26 batch    50\n",
      "Epoch   26 batch   100\n",
      "Epoch   26 batch   150\n",
      "Epoch   26 batch   200\n",
      "Epoch   26 batch   250\n",
      "Epoch   26 batch   300\n",
      "Epoch   26 batch   350\n",
      "Epoch   26 batch   400\n",
      "Epoch   26 batch   450\n",
      "[ 24.8572464] [6]\n",
      "Epoch   26 val.cost 0.000178 val.err 12.15% best\n",
      "Epoch   27 batch     0\n",
      "Epoch   27 batch    50\n",
      "Epoch   27 batch   100\n",
      "Epoch   27 batch   150\n",
      "Epoch   27 batch   200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   27 batch   250\n",
      "Epoch   27 batch   300\n",
      "Epoch   27 batch   350\n",
      "Epoch   27 batch   400\n",
      "Epoch   27 batch   450\n",
      "[ 64.60427094] [65]\n",
      "Epoch   27 val.cost 0.000177 val.err 12.06% best\n",
      "Epoch   28 batch     0\n",
      "Epoch   28 batch    50\n",
      "Epoch   28 batch   100\n",
      "Epoch   28 batch   150\n",
      "Epoch   28 batch   200\n",
      "Epoch   28 batch   250\n",
      "Epoch   28 batch   300\n",
      "Epoch   28 batch   350\n",
      "Epoch   28 batch   400\n",
      "Epoch   28 batch   450\n",
      "[ 74.34131622] [75]\n",
      "Epoch   28 val.cost 0.000177 val.err 11.99% best\n",
      "Epoch   29 batch     0\n",
      "Epoch   29 batch    50\n",
      "Epoch   29 batch   100\n",
      "Epoch   29 batch   150\n",
      "Epoch   29 batch   200\n",
      "Epoch   29 batch   250\n",
      "Epoch   29 batch   300\n",
      "Epoch   29 batch   350\n",
      "Epoch   29 batch   400\n",
      "Epoch   29 batch   450\n",
      "[ 39.44208908] [41]\n",
      "Epoch   29 val.cost 0.000176 val.err 11.93% best\n",
      "Epoch   30 batch     0\n",
      "Epoch   30 batch    50\n",
      "Epoch   30 batch   100\n",
      "Epoch   30 batch   150\n",
      "Epoch   30 batch   200\n",
      "Epoch   30 batch   250\n",
      "Epoch   30 batch   300\n",
      "Epoch   30 batch   350\n",
      "Epoch   30 batch   400\n",
      "Epoch   30 batch   450\n",
      "[ 60.96359253] [61]\n",
      "Epoch   30 val.cost 0.000176 val.err 11.87% best\n",
      "Epoch   31 batch     0\n",
      "Epoch   31 batch    50\n",
      "Epoch   31 batch   100\n",
      "Epoch   31 batch   150\n",
      "Epoch   31 batch   200\n",
      "Epoch   31 batch   250\n",
      "Epoch   31 batch   300\n",
      "Epoch   31 batch   350\n",
      "Epoch   31 batch   400\n",
      "Epoch   31 batch   450\n",
      "[ 49.83952332] [50]\n",
      "Epoch   31 val.cost 0.000176 val.err 11.77% best\n",
      "Epoch   32 batch     0\n",
      "Epoch   32 batch    50\n",
      "Epoch   32 batch   100\n",
      "Epoch   32 batch   150\n",
      "Epoch   32 batch   200\n",
      "Epoch   32 batch   250\n",
      "Epoch   32 batch   300\n",
      "Epoch   32 batch   350\n",
      "Epoch   32 batch   400\n",
      "Epoch   32 batch   450\n",
      "[ 30.48741341] [50]\n",
      "Epoch   32 val.cost 0.000175 val.err 11.71% best\n",
      "Epoch   33 batch     0\n",
      "Epoch   33 batch    50\n",
      "Epoch   33 batch   100\n",
      "Epoch   33 batch   150\n",
      "Epoch   33 batch   200\n",
      "Epoch   33 batch   250\n",
      "Epoch   33 batch   300\n",
      "Epoch   33 batch   350\n",
      "Epoch   33 batch   400\n",
      "Epoch   33 batch   450\n",
      "[ 36.45122147] [35]\n",
      "Epoch   33 val.cost 0.000174 val.err 11.66% best\n",
      "Epoch   34 batch     0\n",
      "Epoch   34 batch    50\n",
      "Epoch   34 batch   100\n",
      "Epoch   34 batch   150\n",
      "Epoch   34 batch   200\n",
      "Epoch   34 batch   250\n",
      "Epoch   34 batch   300\n",
      "Epoch   34 batch   350\n",
      "Epoch   34 batch   400\n",
      "Epoch   34 batch   450\n",
      "[ 41.7263298] [44]\n",
      "Epoch   34 val.cost 0.000174 val.err 11.62% best\n",
      "Epoch   35 batch     0\n",
      "Epoch   35 batch    50\n",
      "Epoch   35 batch   100\n",
      "Epoch   35 batch   150\n",
      "Epoch   35 batch   200\n",
      "Epoch   35 batch   250\n",
      "Epoch   35 batch   300\n",
      "Epoch   35 batch   350\n",
      "Epoch   35 batch   400\n",
      "Epoch   35 batch   450\n",
      "[ 43.94092178] [43]\n",
      "Epoch   35 val.cost 0.000173 val.err 11.57% best\n",
      "Epoch   36 batch     0\n",
      "Epoch   36 batch    50\n",
      "Epoch   36 batch   100\n",
      "Epoch   36 batch   150\n",
      "Epoch   36 batch   200\n",
      "Epoch   36 batch   250\n",
      "Epoch   36 batch   300\n",
      "Epoch   36 batch   350\n",
      "Epoch   36 batch   400\n",
      "Epoch   36 batch   450\n",
      "[ 30.97259712] [16]\n",
      "Epoch   36 val.cost 0.000172 val.err 11.53% best\n",
      "Epoch   37 batch     0\n",
      "Epoch   37 batch    50\n",
      "Epoch   37 batch   100\n",
      "Epoch   37 batch   150\n",
      "Epoch   37 batch   200\n",
      "Epoch   37 batch   250\n",
      "Epoch   37 batch   300\n",
      "Epoch   37 batch   350\n",
      "Epoch   37 batch   400\n",
      "Epoch   37 batch   450\n",
      "[ 38.39702225] [39]\n",
      "Epoch   37 val.cost 0.000172 val.err 11.50% best\n",
      "Epoch   38 batch     0\n",
      "Epoch   38 batch    50\n",
      "Epoch   38 batch   100\n",
      "Epoch   38 batch   150\n",
      "Epoch   38 batch   200\n",
      "Epoch   38 batch   250\n",
      "Epoch   38 batch   300\n",
      "Epoch   38 batch   350\n",
      "Epoch   38 batch   400\n",
      "Epoch   38 batch   450\n",
      "[ 40.59032822] [40]\n",
      "Epoch   38 val.cost 0.000172 val.err 11.48% best\n",
      "Epoch   39 batch     0\n",
      "Epoch   39 batch    50\n",
      "Epoch   39 batch   100\n",
      "Epoch   39 batch   150\n",
      "Epoch   39 batch   200\n",
      "Epoch   39 batch   250\n",
      "Epoch   39 batch   300\n",
      "Epoch   39 batch   350\n",
      "Epoch   39 batch   400\n",
      "Epoch   39 batch   450\n",
      "[ 33.3663559] [34]\n",
      "Epoch   39 val.cost 0.000172 val.err 11.46% best\n",
      "Epoch   40 batch     0\n",
      "Epoch   40 batch    50\n",
      "Epoch   40 batch   100\n",
      "Epoch   40 batch   150\n",
      "Epoch   40 batch   200\n",
      "Epoch   40 batch   250\n",
      "Epoch   40 batch   300\n",
      "Epoch   40 batch   350\n",
      "Epoch   40 batch   400\n",
      "Epoch   40 batch   450\n",
      "[ 30.22143173] [51]\n",
      "Epoch   40 val.cost 0.000172 val.err 11.45% best\n",
      "Epoch   41 batch     0\n",
      "Epoch   41 batch    50\n",
      "Epoch   41 batch   100\n",
      "Epoch   41 batch   150\n",
      "Epoch   41 batch   200\n",
      "Epoch   41 batch   250\n",
      "Epoch   41 batch   300\n",
      "Epoch   41 batch   350\n",
      "Epoch   41 batch   400\n",
      "Epoch   41 batch   450\n",
      "[ 86.69436646] [89]\n",
      "Epoch   41 val.cost 0.000173 val.err 11.43% best\n",
      "Epoch   42 batch     0\n",
      "Epoch   42 batch    50\n",
      "Epoch   42 batch   100\n",
      "Epoch   42 batch   150\n",
      "Epoch   42 batch   200\n",
      "Epoch   42 batch   250\n",
      "Epoch   42 batch   300\n",
      "Epoch   42 batch   350\n",
      "Epoch   42 batch   400\n",
      "Epoch   42 batch   450\n",
      "[ 45.61682129] [44]\n",
      "Epoch   42 val.cost 0.000172 val.err 11.42% best\n",
      "Epoch   43 batch     0\n",
      "Epoch   43 batch    50\n",
      "Epoch   43 batch   100\n",
      "Epoch   43 batch   150\n",
      "Epoch   43 batch   200\n",
      "Epoch   43 batch   250\n",
      "Epoch   43 batch   300\n",
      "Epoch   43 batch   350\n",
      "Epoch   43 batch   400\n",
      "Epoch   43 batch   450\n",
      "[ 26.20433807] [26]\n",
      "Epoch   43 val.cost 0.000170 val.err 11.41% best\n",
      "Epoch   44 batch     0\n",
      "Epoch   44 batch    50\n",
      "Epoch   44 batch   100\n",
      "Epoch   44 batch   150\n",
      "Epoch   44 batch   200\n",
      "Epoch   44 batch   250\n",
      "Epoch   44 batch   300\n",
      "Epoch   44 batch   350\n",
      "Epoch   44 batch   400\n",
      "Epoch   44 batch   450\n",
      "[ 35.74238205] [50]\n",
      "Epoch   44 val.cost 0.000174 val.err 11.39% best\n",
      "Epoch   45 batch     0\n",
      "Epoch   45 batch    50\n",
      "Epoch   45 batch   100\n",
      "Epoch   45 batch   150\n",
      "Epoch   45 batch   200\n",
      "Epoch   45 batch   250\n",
      "Epoch   45 batch   300\n",
      "Epoch   45 batch   350\n",
      "Epoch   45 batch   400\n",
      "Epoch   45 batch   450\n",
      "[ 26.7660656] [14]\n",
      "Epoch   45 val.cost 0.000172 val.err 11.38% best\n",
      "Epoch   46 batch     0\n",
      "Epoch   46 batch    50\n",
      "Epoch   46 batch   100\n",
      "Epoch   46 batch   150\n",
      "Epoch   46 batch   200\n",
      "Epoch   46 batch   250\n",
      "Epoch   46 batch   300\n",
      "Epoch   46 batch   350\n",
      "Epoch   46 batch   400\n",
      "Epoch   46 batch   450\n",
      "[ 44.82917786] [46]\n",
      "Epoch   46 val.cost 0.000171 val.err 11.37% best\n",
      "Epoch   47 batch     0\n",
      "Epoch   47 batch    50\n",
      "Epoch   47 batch   100\n",
      "Epoch   47 batch   150\n",
      "Epoch   47 batch   200\n",
      "Epoch   47 batch   250\n",
      "Epoch   47 batch   300\n",
      "Epoch   47 batch   350\n",
      "Epoch   47 batch   400\n",
      "Epoch   47 batch   450\n",
      "[ 8.53160381] [9]\n",
      "Epoch   47 val.cost 0.000171 val.err 11.36% best\n",
      "Epoch   48 batch     0\n",
      "Epoch   48 batch    50\n",
      "Epoch   48 batch   100\n",
      "Epoch   48 batch   150\n",
      "Epoch   48 batch   200\n",
      "Epoch   48 batch   250\n",
      "Epoch   48 batch   300\n",
      "Epoch   48 batch   350\n",
      "Epoch   48 batch   400\n",
      "Epoch   48 batch   450\n",
      "[ 46.17623901] [14]\n",
      "Epoch   48 val.cost 0.000171 val.err 11.35% best\n",
      "Epoch   49 batch     0\n",
      "Epoch   49 batch    50\n",
      "Epoch   49 batch   100\n",
      "Epoch   49 batch   150\n",
      "Epoch   49 batch   200\n",
      "Epoch   49 batch   250\n",
      "Epoch   49 batch   300\n",
      "Epoch   49 batch   350\n",
      "Epoch   49 batch   400\n",
      "Epoch   49 batch   450\n",
      "[ 34.23125458] [12]\n",
      "Epoch   49 val.cost 0.000172 val.err 11.33% best\n",
      "Epoch   50 batch     0\n",
      "Epoch   50 batch    50\n",
      "Epoch   50 batch   100\n",
      "Epoch   50 batch   150\n",
      "Epoch   50 batch   200\n",
      "Epoch   50 batch   250\n",
      "Epoch   50 batch   300\n",
      "Epoch   50 batch   350\n",
      "Epoch   50 batch   400\n",
      "Epoch   50 batch   450\n",
      "[ 77.94812775] [76]\n",
      "Epoch   50 val.cost 0.000172 val.err 11.33% best\n",
      "Epoch   51 batch     0\n",
      "Epoch   51 batch    50\n",
      "Epoch   51 batch   100\n",
      "Epoch   51 batch   150\n",
      "Epoch   51 batch   200\n",
      "Epoch   51 batch   250\n",
      "Epoch   51 batch   300\n",
      "Epoch   51 batch   350\n",
      "Epoch   51 batch   400\n",
      "Epoch   51 batch   450\n",
      "[ 47.49144745] [47]\n",
      "Epoch   51 val.cost 0.000172 val.err 11.34% stopping   1\n",
      "Epoch   52 batch     0\n",
      "Epoch   52 batch    50\n",
      "Epoch   52 batch   100\n",
      "Epoch   52 batch   150\n",
      "Epoch   52 batch   200\n",
      "Epoch   52 batch   250\n",
      "Epoch   52 batch   300\n",
      "Epoch   52 batch   350\n",
      "Epoch   52 batch   400\n",
      "Epoch   52 batch   450\n",
      "[ 40.6908493] [10]\n",
      "Epoch   52 val.cost 0.000170 val.err 11.35% stopping   2\n",
      "Epoch   53 batch     0\n",
      "Epoch   53 batch    50\n",
      "Epoch   53 batch   100\n",
      "Epoch   53 batch   150\n",
      "Epoch   53 batch   200\n",
      "Epoch   53 batch   250\n",
      "Epoch   53 batch   300\n",
      "Epoch   53 batch   350\n",
      "Epoch   53 batch   400\n",
      "Epoch   53 batch   450\n",
      "[ 60.39618683] [62]\n",
      "Epoch   53 val.cost 0.000171 val.err 11.34% stopping   3\n",
      "Epoch   54 batch     0\n",
      "Epoch   54 batch    50\n",
      "Epoch   54 batch   100\n",
      "Epoch   54 batch   150\n",
      "Epoch   54 batch   200\n",
      "Epoch   54 batch   250\n",
      "Epoch   54 batch   300\n",
      "Epoch   54 batch   350\n",
      "Epoch   54 batch   400\n",
      "Epoch   54 batch   450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46.08054733] [45]\n",
      "Epoch   54 val.cost 0.000170 val.err 11.31% best\n",
      "Epoch   55 batch     0\n",
      "Epoch   55 batch    50\n",
      "Epoch   55 batch   100\n",
      "Epoch   55 batch   150\n",
      "Epoch   55 batch   200\n",
      "Epoch   55 batch   250\n",
      "Epoch   55 batch   300\n",
      "Epoch   55 batch   350\n",
      "Epoch   55 batch   400\n",
      "Epoch   55 batch   450\n",
      "[ 22.25263977] [22]\n",
      "Epoch   55 val.cost 0.000171 val.err 11.32% stopping   1\n",
      "Epoch   56 batch     0\n",
      "Epoch   56 batch    50\n",
      "Epoch   56 batch   100\n",
      "Epoch   56 batch   150\n",
      "Epoch   56 batch   200\n",
      "Epoch   56 batch   250\n",
      "Epoch   56 batch   300\n",
      "Epoch   56 batch   350\n",
      "Epoch   56 batch   400\n",
      "Epoch   56 batch   450\n",
      "[ 44.19645309] [44]\n",
      "Epoch   56 val.cost 0.000173 val.err 11.32% stopping   2\n",
      "Epoch   57 batch     0\n",
      "Epoch   57 batch    50\n",
      "Epoch   57 batch   100\n",
      "Epoch   57 batch   150\n",
      "Epoch   57 batch   200\n",
      "Epoch   57 batch   250\n",
      "Epoch   57 batch   300\n",
      "Epoch   57 batch   350\n",
      "Epoch   57 batch   400\n",
      "Epoch   57 batch   450\n",
      "[ 34.18968201] [21]\n",
      "Epoch   57 val.cost 0.000172 val.err 11.31% best\n",
      "Epoch   58 batch     0\n",
      "Epoch   58 batch    50\n",
      "Epoch   58 batch   100\n",
      "Epoch   58 batch   150\n",
      "Epoch   58 batch   200\n",
      "Epoch   58 batch   250\n",
      "Epoch   58 batch   300\n",
      "Epoch   58 batch   350\n",
      "Epoch   58 batch   400\n",
      "Epoch   58 batch   450\n",
      "[ 31.20228386] [31]\n",
      "Epoch   58 val.cost 0.000173 val.err 11.29% best\n",
      "Epoch   59 batch     0\n",
      "Epoch   59 batch    50\n",
      "Epoch   59 batch   100\n",
      "Epoch   59 batch   150\n",
      "Epoch   59 batch   200\n",
      "Epoch   59 batch   250\n",
      "Epoch   59 batch   300\n",
      "Epoch   59 batch   350\n",
      "Epoch   59 batch   400\n",
      "Epoch   59 batch   450\n",
      "[ 48.3772583] [5]\n",
      "Epoch   59 val.cost 0.000176 val.err 11.32% stopping   1\n",
      "Epoch   60 batch     0\n",
      "Epoch   60 batch    50\n",
      "Epoch   60 batch   100\n",
      "Epoch   60 batch   150\n",
      "Epoch   60 batch   200\n",
      "Epoch   60 batch   250\n",
      "Epoch   60 batch   300\n",
      "Epoch   60 batch   350\n",
      "Epoch   60 batch   400\n",
      "Epoch   60 batch   450\n",
      "[ 30.4070015] [31]\n",
      "Epoch   60 val.cost 0.000175 val.err 11.30% stopping   2\n",
      "Epoch   61 batch     0\n",
      "Epoch   61 batch    50\n",
      "Epoch   61 batch   100\n",
      "Epoch   61 batch   150\n",
      "Epoch   61 batch   200\n",
      "Epoch   61 batch   250\n",
      "Epoch   61 batch   300\n",
      "Epoch   61 batch   350\n",
      "Epoch   61 batch   400\n",
      "Epoch   61 batch   450\n",
      "[ 15.49470425] [15]\n",
      "Epoch   61 val.cost 0.000174 val.err 11.32% stopping   3\n",
      "Epoch   62 batch     0\n",
      "Epoch   62 batch    50\n",
      "Epoch   62 batch   100\n",
      "Epoch   62 batch   150\n",
      "Epoch   62 batch   200\n",
      "Epoch   62 batch   250\n",
      "Epoch   62 batch   300\n",
      "Epoch   62 batch   350\n",
      "Epoch   62 batch   400\n",
      "Epoch   62 batch   450\n",
      "[ 54.04379654] [54]\n",
      "Epoch   62 val.cost 0.000175 val.err 11.30% stopping   4\n",
      "Epoch   63 batch     0\n",
      "Epoch   63 batch    50\n",
      "Epoch   63 batch   100\n",
      "Epoch   63 batch   150\n",
      "Epoch   63 batch   200\n",
      "Epoch   63 batch   250\n",
      "Epoch   63 batch   300\n",
      "Epoch   63 batch   350\n",
      "Epoch   63 batch   400\n",
      "Epoch   63 batch   450\n",
      "[ 18.49946785] [19]\n",
      "Epoch   63 val.cost 0.000175 val.err 11.32% stopping   5\n",
      "Epoch   64 batch     0\n",
      "Epoch   64 batch    50\n",
      "Epoch   64 batch   100\n",
      "Epoch   64 batch   150\n",
      "Epoch   64 batch   200\n",
      "Epoch   64 batch   250\n",
      "Epoch   64 batch   300\n",
      "Epoch   64 batch   350\n",
      "Epoch   64 batch   400\n",
      "Epoch   64 batch   450\n",
      "[ 34.86988068] [34]\n",
      "Epoch   64 val.cost 0.000173 val.err 11.31% stopping   6\n",
      "Epoch   65 batch     0\n",
      "Epoch   65 batch    50\n",
      "Epoch   65 batch   100\n",
      "Epoch   65 batch   150\n",
      "Epoch   65 batch   200\n",
      "Epoch   65 batch   250\n",
      "Epoch   65 batch   300\n",
      "Epoch   65 batch   350\n",
      "Epoch   65 batch   400\n",
      "Epoch   65 batch   450\n",
      "[ 28.85623169] [28]\n",
      "Epoch   65 val.cost 0.000174 val.err 11.32% stopping   7\n",
      "Epoch   66 batch     0\n",
      "Epoch   66 batch    50\n",
      "Epoch   66 batch   100\n",
      "Epoch   66 batch   150\n",
      "Epoch   66 batch   200\n",
      "Epoch   66 batch   250\n",
      "Epoch   66 batch   300\n",
      "Epoch   66 batch   350\n",
      "Epoch   66 batch   400\n",
      "Epoch   66 batch   450\n",
      "[ 172.24858093] [176]\n",
      "Epoch   66 val.cost 0.000172 val.err 11.31% stopping   8\n",
      "Epoch   67 batch     0\n",
      "Epoch   67 batch    50\n",
      "Epoch   67 batch   100\n",
      "Epoch   67 batch   150\n",
      "Epoch   67 batch   200\n",
      "Epoch   67 batch   250\n",
      "Epoch   67 batch   300\n",
      "Epoch   67 batch   350\n",
      "Epoch   67 batch   400\n",
      "Epoch   67 batch   450\n",
      "[ 35.22583008] [35]\n",
      "Epoch   67 val.cost 0.000173 val.err 11.32% stopping   9\n",
      "Epoch   68 batch     0\n",
      "Epoch   68 batch    50\n",
      "Epoch   68 batch   100\n",
      "Epoch   68 batch   150\n",
      "Epoch   68 batch   200\n",
      "Epoch   68 batch   250\n",
      "Epoch   68 batch   300\n",
      "Epoch   68 batch   350\n",
      "Epoch   68 batch   400\n",
      "Epoch   68 batch   450\n",
      "[ 26.73947906] [31]\n",
      "Epoch   68 val.cost 0.000173 val.err 11.32% stopping  10\n",
      "Early stopping triggered: Step:      33974, val.err 11.32%\n",
      "best model saved to: ./best_model/model_20180605_141846\n",
      "Total time: 2862.406177\n",
      "INFO:tensorflow:Restoring parameters from ./best_model/model_20180605_141846\n",
      "Test Err: 11.95%\n",
      "Predicting...\n",
      "Predict End\n"
     ]
    }
   ],
   "source": [
    "predicted_values = dnn(dfa_X, dfa_Y, df2a_X, df2a_y, df3a_X, df3a_y, dfwa_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = pd.DataFrame({'PM2.5':predicted_values[:,0]})\n",
    "dw['PM2.5']=predicted_df['PM2.5']\n",
    "dw.to_csv('./predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
