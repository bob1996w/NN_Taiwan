{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tensorflow.contrib.layers import fully_connected, batch_norm\n",
    "import math\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./DL_final_project/DL_Taiwan_data/sinica/201701_Taiwan.csv',\n",
    "                 usecols=['Date','Time','PM2.5','PM10','PM1','Temperature','Humidity','lon','lat'])\n",
    "#把201701_Taiwan.csv的header的' lat',' lon'改成'lat','lon' (多了空格)\n",
    "train_for_taiwan = True # filter out non-Taiwan\n",
    "#len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_for_taiwan:\n",
    "    df = df[(df['lat']>= 22 )& (df['lat'] <= 25)&(df['lon']>=120)&(df['lon']<=122)]\n",
    "df = df.assign(Timestamp = pd.to_datetime(df['Date']+' '+df['Time']))\n",
    "df = df.assign(Hour = df['Timestamp'].dt.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X = df[['Hour','PM10','PM1','Temperature','Humidity','lon','lat']]\n",
    "df_X = df_X.values\n",
    "df_Y = df[['PM2.5']]\n",
    "df_Y = df_Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_logdir = \"tf_logs\"\n",
    "batch_log_step = 50\n",
    "early_stopping_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dnn(X_1, y_1, X_2, y_2, X_3, y_3):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # check folder\n",
    "    export_check_num = 1\n",
    "    export_dir = './final_model/'\n",
    "    while os.path.exists(export_dir):\n",
    "        export_check_num += 1\n",
    "        export_dir = './final_model_'+str(export_check_num)+'/'\n",
    "    \n",
    "    print(\"model will be exported in\",export_dir)\n",
    "    \n",
    "    # logs\n",
    "    start_time = datetime.now()\n",
    "    now = start_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    logdir = \"./{}/run-{}\".format(root_logdir, now)\n",
    "    print(\"now=\",now)\n",
    "    \n",
    "    # dnn graph defs\n",
    "    n_input = 7\n",
    "    n_epochs = 100\n",
    "    n_hidden = [100,100,10]\n",
    "    act_fn = tf.nn.sigmoid\n",
    "    learning_rate = 0.001\n",
    "    batch_normalization = False\n",
    "    batch_size = 10000\n",
    "    #batch_size = 1000 #小範圍測試用\n",
    "    mult_bias = 1000\n",
    "\n",
    "    # I/O\n",
    "    with tf.name_scope(\"Input\"):\n",
    "        X = tf.placeholder(tf.float32, [None, n_input], name=\"X\")\n",
    "        is_training = tf.placeholder(tf.bool, shape=(), name=\"is_training\")\n",
    "    with tf.name_scope(\"Output\"):\n",
    "        y = tf.placeholder(tf.float32, [None, 1], name=\"y\")\n",
    "        y_biased = y/mult_bias\n",
    "    \n",
    "    # batch norm \n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    with tf.name_scope(\"BatchNormArgs\"):\n",
    "        bn_params = {\n",
    "            'is_training': is_training,\n",
    "            'decay': 0.99,\n",
    "            'updates_collections': None,\n",
    "            'scale': True\n",
    "        }\n",
    "    \n",
    "    # DNN\n",
    "    with tf.name_scope(\"DNN\"):\n",
    "        with tf.contrib.framework.arg_scope(\n",
    "                [fully_connected],\n",
    "                weights_initializer = he_init,\n",
    "                normalizer_fn = batch_norm if batch_normalization else None,\n",
    "                normalizer_params = bn_params if batch_normalization else None\n",
    "                ):\n",
    "            h1=fully_connected(X ,n_hidden[0],activation_fn=act_fn,scope=\"h1\")\n",
    "            h2=fully_connected(h1,n_hidden[1],activation_fn=act_fn,scope=\"h2\")\n",
    "            h3=fully_connected(h2,n_hidden[2],activation_fn=act_fn,scope=\"h3\")\n",
    "            logits=fully_connected(h3, 1, activation_fn=act_fn,scope=\"out\")\n",
    "    \n",
    "    with tf.name_scope(\"Cost\"):\n",
    "        #cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y), name=\"cost\")\n",
    "        cost = tf.losses.mean_squared_error(logits, y_biased)\n",
    "    with tf.name_scope(\"AdamOptimizer\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "        minimizer = optimizer.minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.name_scope(\"ModelSaver\"):\n",
    "        saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.name_scope(\"Predict\"):\n",
    "        predict = tf.multiply(logits, mult_bias, name=\"predict\")\n",
    "        \n",
    "    with tf.name_scope(\"Error\"):\n",
    "        ave_of_batch_y = tf.reduce_mean(y_biased)\n",
    "        error = tf.abs(logits - y_biased)/ave_of_batch_y\n",
    "        relative_err = tf.reduce_mean(error)\n",
    "    \n",
    "    with tf.name_scope(\"Summaries-Train\"):\n",
    "        cost_summary = tf.summary.scalar('cost_function',cost)\n",
    "        error_summary = tf.summary.scalar('relative_err',relative_err)\n",
    "    with tf.name_scope(\"Summaries-Validation\"):\n",
    "        v_cost_summary = tf.summary.scalar('v_cost_function',cost)\n",
    "        v_error_summary = tf.summary.scalar('v_relative_err',relative_err)\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        total_batch = len(X_1)//batch_size\n",
    "        #total_batch = validation_idx_start//batch_size\n",
    "        print(\"Total batch:\",total_batch)\n",
    "        #X_va, y_va = dfa_X[validation_idx_start:test_idx_start], dfa_Y[validation_idx_start:test_idx_start]\n",
    "        X_va = X_2\n",
    "        y_va = y_2\n",
    "        X_test = X_3\n",
    "        y_test = y_3\n",
    "        \n",
    "        best_va_err_triggered = False\n",
    "        best_va_err = 0\n",
    "        early_stopping_triggered = False\n",
    "        stopping_epoch = 0\n",
    "        step = 0\n",
    "        save_path = \"\"\n",
    "        best_save_path = \"\"\n",
    "        \n",
    "        perm = np.arange(len(X_1))\n",
    "        np.random.shuffle(perm)\n",
    "        X_t = X_1[perm]\n",
    "        y_t = y_1[perm]\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            for batch in range(total_batch):\n",
    "                X_ba = X_t[batch*batch_size: (batch+1)*batch_size]\n",
    "                y_ba = y_t[batch*batch_size: (batch+1)*batch_size]\n",
    "                _, c = sess.run([minimizer, cost], feed_dict = {is_training: True, X:X_ba, y:y_ba})\n",
    "                \n",
    "                if batch % batch_log_step == 0:\n",
    "                    print(\"Epoch %4d batch %5d\"%(epoch,batch))\n",
    "                    cost_summary_str = cost_summary.eval(feed_dict={is_training:False, X:X_ba, y:y_ba})\n",
    "                    step = epoch * total_batch + batch\n",
    "                    file_writer.add_summary(cost_summary_str, step)\n",
    "                    error_summary_str = error_summary.eval(feed_dict={is_training:False, X:X_ba, y:y_ba})\n",
    "                    file_writer.add_summary(error_summary_str, step)\n",
    "            \n",
    "            save_path = saver.save(sess, \"./checkpoint/model_\"+now+\".ckpt\")\n",
    "            va_err, va_cost = sess.run([relative_err, cost], feed_dict={is_training:False, X:X_va, y:y_va})\n",
    "            va_l = sess.run(predict, feed_dict={is_training:False, X:X_va, y:y_va})\n",
    "            rnd_result_idx = random.randint(0, len(X_va)-1)\n",
    "            \n",
    "            print(va_l[rnd_result_idx], y_va[rnd_result_idx]) # print 1st prediction result\n",
    "            v_error_summary_str = v_error_summary.eval(feed_dict={is_training:False, X:X_va, y:y_va})\n",
    "            file_writer.add_summary(v_error_summary_str, step)\n",
    "            v_cost_summary_str = v_cost_summary.eval(feed_dict={is_training:False, X:X_va, y:y_va})\n",
    "            file_writer.add_summary(v_cost_summary_str, step)\n",
    "            print(\"Epoch %4d val.cost %3.6f val.err %3.2f%%\"%(epoch,va_cost,va_err*100),end=\" \")\n",
    "            \n",
    "            if best_va_err_triggered:\n",
    "                if va_err < best_va_err:\n",
    "                    print(\"best\")\n",
    "                    stopping_epoch = 0\n",
    "                    best_va_err = va_err\n",
    "                    \n",
    "                    best_save_path = saver.save(sess, \"./best_model/model_\"+now)\n",
    "                else:\n",
    "                    stopping_epoch += 1\n",
    "                    print(\"stopping %3d\"%stopping_epoch)\n",
    "                if stopping_epoch >= early_stopping_epochs:\n",
    "                    early_stopping_triggered = True\n",
    "                    print(\"Early stopping triggered: Step: %10d, val.err %3.2f%%\"%(step, va_err*100))\n",
    "            else:\n",
    "                best_va_err = va_err\n",
    "                best_va_err_triggered = True\n",
    "                print(\"best\")\n",
    "                best_save_path = saver.save(sess, \"./best_model/model_\"+now)\n",
    "            \n",
    "            if early_stopping_triggered:\n",
    "                break\n",
    "        \n",
    "        finish_time = datetime.now()\n",
    "        print(\"best model saved to:\", best_save_path)\n",
    "        file_writer.close()\n",
    "        elapse_time = finish_time - start_time\n",
    "        total_seconds = elapse_time.total_seconds()\n",
    "        print(\"Total time:\", total_seconds)\n",
    "        \n",
    "        #X_test = dfa_X[test_idx_start:idx_end]\n",
    "        #y_test = dfa_Y[test_idx_start:idx_end]\n",
    "        saver.restore(sess, \"./best_model/model_\"+now)\n",
    "        best_err = relative_err.eval({is_training: False, X: X_test, y: y_test})\n",
    "        print(\"Test Err: %3.2f%%\"%(best_err*100))\n",
    "        \n",
    "        \n",
    "        builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "        builder.add_meta_graph_and_variables(sess, [\"tag\"], signature_def_map= {\n",
    "            \"model\": tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "                inputs= {\"X\": X, \"is_training\": is_training},\n",
    "                outputs= {\"predict\": predict})\n",
    "        })\n",
    "        builder.save()\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"Predicting...\")\n",
    "        predict_values = sess.run(predict, feed_dict={is_training: False, X: X_w})\n",
    "        print(\"Predict End\")\n",
    "        return predict_values\n",
    "        \"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df2: validation\n",
    "# df3: test\n",
    "df_v = pd.read_csv('./DL_final_project/DL_Taiwan_data/sinica/201702_Taiwan.csv',\n",
    "                 usecols=['Date','Time','PM2.5','PM10','PM1','Temperature','Humidity','lon','lat'])\n",
    "test_idx_start = math.floor(len(df_v)*0.5)\n",
    "df2 = df_v[:test_idx_start]\n",
    "df3 = df_v[test_idx_start:]\n",
    "if train_for_taiwan:\n",
    "    df2 = df2[(df2['lat']>= 22 )& (df2['lat'] <= 25)&(df2['lon']>=120)&(df2['lon']<=122)]\n",
    "df2 = df2.assign(Timestamp = pd.to_datetime(df2['Date']+' '+df2['Time']))\n",
    "df3 = df3.assign(Timestamp = pd.to_datetime(df3['Date']+' '+df3['Time']))\n",
    "df2 = df2.assign(Hour = df2['Timestamp'].dt.hour)\n",
    "df3 = df3.assign(Hour = df3['Timestamp'].dt.hour)\n",
    "df2_X = df2[['Hour','PM10','PM1','Temperature','Humidity','lon','lat']]\n",
    "df2_y = df2[['PM2.5']]\n",
    "df3_X = df3[['Hour','PM10','PM1','Temperature','Humidity','lon','lat']]\n",
    "df3_y = df3[['PM2.5']]\n",
    "df2_X = df2_X.values\n",
    "df2_y = df2_y.values\n",
    "df3_X = df3_X.values\n",
    "df3_y = df3_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model will be exported in ./final_model/\n",
      "now= 20180608_010508\n",
      "Total batch: 493\n",
      "Epoch    0 batch     0\n",
      "Epoch    0 batch    50\n",
      "Epoch    0 batch   100\n",
      "Epoch    0 batch   150\n",
      "Epoch    0 batch   200\n",
      "Epoch    0 batch   250\n",
      "Epoch    0 batch   300\n",
      "Epoch    0 batch   350\n",
      "Epoch    0 batch   400\n",
      "Epoch    0 batch   450\n",
      "[ 40.47767639] [33]\n",
      "Epoch    0 val.cost 0.000362 val.err 28.16% best\n",
      "Epoch    1 batch     0\n",
      "Epoch    1 batch    50\n",
      "Epoch    1 batch   100\n",
      "Epoch    1 batch   150\n",
      "Epoch    1 batch   200\n",
      "Epoch    1 batch   250\n",
      "Epoch    1 batch   300\n",
      "Epoch    1 batch   350\n",
      "Epoch    1 batch   400\n",
      "Epoch    1 batch   450\n",
      "[ 31.44128609] [24]\n",
      "Epoch    1 val.cost 0.000252 val.err 20.28% best\n",
      "Epoch    2 batch     0\n",
      "Epoch    2 batch    50\n",
      "Epoch    2 batch   100\n",
      "Epoch    2 batch   150\n",
      "Epoch    2 batch   200\n",
      "Epoch    2 batch   250\n",
      "Epoch    2 batch   300\n",
      "Epoch    2 batch   350\n",
      "Epoch    2 batch   400\n",
      "Epoch    2 batch   450\n",
      "[ 27.41244507] [1]\n",
      "Epoch    2 val.cost 0.000231 val.err 18.08% best\n",
      "Epoch    3 batch     0\n",
      "Epoch    3 batch    50\n",
      "Epoch    3 batch   100\n",
      "Epoch    3 batch   150\n",
      "Epoch    3 batch   200\n",
      "Epoch    3 batch   250\n",
      "Epoch    3 batch   300\n",
      "Epoch    3 batch   350\n",
      "Epoch    3 batch   400\n",
      "Epoch    3 batch   450\n",
      "[ 47.95358276] [47]\n",
      "Epoch    3 val.cost 0.000224 val.err 17.08% best\n",
      "Epoch    4 batch     0\n",
      "Epoch    4 batch    50\n",
      "Epoch    4 batch   100\n",
      "Epoch    4 batch   150\n",
      "Epoch    4 batch   200\n",
      "Epoch    4 batch   250\n",
      "Epoch    4 batch   300\n",
      "Epoch    4 batch   350\n",
      "Epoch    4 batch   400\n",
      "Epoch    4 batch   450\n",
      "[ 52.55426025] [55]\n",
      "Epoch    4 val.cost 0.000221 val.err 16.57% best\n",
      "Epoch    5 batch     0\n",
      "Epoch    5 batch    50\n",
      "Epoch    5 batch   100\n",
      "Epoch    5 batch   150\n",
      "Epoch    5 batch   200\n",
      "Epoch    5 batch   250\n",
      "Epoch    5 batch   300\n",
      "Epoch    5 batch   350\n",
      "Epoch    5 batch   400\n",
      "Epoch    5 batch   450\n",
      "[ 24.36937523] [20]\n",
      "Epoch    5 val.cost 0.000219 val.err 16.25% best\n",
      "Epoch    6 batch     0\n",
      "Epoch    6 batch    50\n",
      "Epoch    6 batch   100\n",
      "Epoch    6 batch   150\n",
      "Epoch    6 batch   200\n",
      "Epoch    6 batch   250\n",
      "Epoch    6 batch   300\n",
      "Epoch    6 batch   350\n",
      "Epoch    6 batch   400\n",
      "Epoch    6 batch   450\n",
      "[ 32.98526382] [32]\n",
      "Epoch    6 val.cost 0.000218 val.err 16.06% best\n",
      "Epoch    7 batch     0\n",
      "Epoch    7 batch    50\n",
      "Epoch    7 batch   100\n",
      "Epoch    7 batch   150\n",
      "Epoch    7 batch   200\n",
      "Epoch    7 batch   250\n",
      "Epoch    7 batch   300\n",
      "Epoch    7 batch   350\n",
      "Epoch    7 batch   400\n",
      "Epoch    7 batch   450\n",
      "[ 77.04824066] [78]\n",
      "Epoch    7 val.cost 0.000217 val.err 15.93% best\n",
      "Epoch    8 batch     0\n",
      "Epoch    8 batch    50\n",
      "Epoch    8 batch   100\n",
      "Epoch    8 batch   150\n",
      "Epoch    8 batch   200\n",
      "Epoch    8 batch   250\n",
      "Epoch    8 batch   300\n",
      "Epoch    8 batch   350\n",
      "Epoch    8 batch   400\n",
      "Epoch    8 batch   450\n",
      "[ 37.70869827] [36]\n",
      "Epoch    8 val.cost 0.000214 val.err 15.83% best\n",
      "Epoch    9 batch     0\n",
      "Epoch    9 batch    50\n",
      "Epoch    9 batch   100\n",
      "Epoch    9 batch   150\n",
      "Epoch    9 batch   200\n",
      "Epoch    9 batch   250\n",
      "Epoch    9 batch   300\n",
      "Epoch    9 batch   350\n",
      "Epoch    9 batch   400\n",
      "Epoch    9 batch   450\n",
      "[ 32.35531998] [33]\n",
      "Epoch    9 val.cost 0.000213 val.err 15.76% best\n",
      "Epoch   10 batch     0\n",
      "Epoch   10 batch    50\n",
      "Epoch   10 batch   100\n",
      "Epoch   10 batch   150\n",
      "Epoch   10 batch   200\n",
      "Epoch   10 batch   250\n",
      "Epoch   10 batch   300\n",
      "Epoch   10 batch   350\n",
      "Epoch   10 batch   400\n",
      "Epoch   10 batch   450\n",
      "[ 24.05872345] [32]\n",
      "Epoch   10 val.cost 0.000212 val.err 15.72% best\n",
      "Epoch   11 batch     0\n",
      "Epoch   11 batch    50\n",
      "Epoch   11 batch   100\n",
      "Epoch   11 batch   150\n",
      "Epoch   11 batch   200\n",
      "Epoch   11 batch   250\n",
      "Epoch   11 batch   300\n",
      "Epoch   11 batch   350\n",
      "Epoch   11 batch   400\n",
      "Epoch   11 batch   450\n",
      "[ 24.04486847] [5]\n",
      "Epoch   11 val.cost 0.000210 val.err 15.68% best\n",
      "Epoch   12 batch     0\n",
      "Epoch   12 batch    50\n",
      "Epoch   12 batch   100\n",
      "Epoch   12 batch   150\n",
      "Epoch   12 batch   200\n",
      "Epoch   12 batch   250\n",
      "Epoch   12 batch   300\n",
      "Epoch   12 batch   350\n",
      "Epoch   12 batch   400\n",
      "Epoch   12 batch   450\n",
      "[ 24.03806496] [21]\n",
      "Epoch   12 val.cost 0.000210 val.err 15.66% best\n",
      "Epoch   13 batch     0\n",
      "Epoch   13 batch    50\n",
      "Epoch   13 batch   100\n",
      "Epoch   13 batch   150\n",
      "Epoch   13 batch   200\n",
      "Epoch   13 batch   250\n",
      "Epoch   13 batch   300\n",
      "Epoch   13 batch   350\n",
      "Epoch   13 batch   400\n",
      "Epoch   13 batch   450\n",
      "[ 90.47142792] [98]\n",
      "Epoch   13 val.cost 0.000209 val.err 15.64% best\n",
      "Epoch   14 batch     0\n",
      "Epoch   14 batch    50\n",
      "Epoch   14 batch   100\n",
      "Epoch   14 batch   150\n",
      "Epoch   14 batch   200\n",
      "Epoch   14 batch   250\n",
      "Epoch   14 batch   300\n",
      "Epoch   14 batch   350\n",
      "Epoch   14 batch   400\n",
      "Epoch   14 batch   450\n",
      "[ 57.81128693] [60]\n",
      "Epoch   14 val.cost 0.000208 val.err 15.60% best\n",
      "Epoch   15 batch     0\n",
      "Epoch   15 batch    50\n",
      "Epoch   15 batch   100\n",
      "Epoch   15 batch   150\n",
      "Epoch   15 batch   200\n",
      "Epoch   15 batch   250\n",
      "Epoch   15 batch   300\n",
      "Epoch   15 batch   350\n",
      "Epoch   15 batch   400\n",
      "Epoch   15 batch   450\n",
      "[ 60.42433548] [60]\n",
      "Epoch   15 val.cost 0.000206 val.err 15.49% best\n",
      "Epoch   16 batch     0\n",
      "Epoch   16 batch    50\n",
      "Epoch   16 batch   100\n",
      "Epoch   16 batch   150\n",
      "Epoch   16 batch   200\n",
      "Epoch   16 batch   250\n",
      "Epoch   16 batch   300\n",
      "Epoch   16 batch   350\n",
      "Epoch   16 batch   400\n",
      "Epoch   16 batch   450\n",
      "[ 15.57860184] [11]\n",
      "Epoch   16 val.cost 0.000186 val.err 13.28% best\n",
      "Epoch   17 batch     0\n",
      "Epoch   17 batch    50\n",
      "Epoch   17 batch   100\n",
      "Epoch   17 batch   150\n",
      "Epoch   17 batch   200\n",
      "Epoch   17 batch   250\n",
      "Epoch   17 batch   300\n",
      "Epoch   17 batch   350\n",
      "Epoch   17 batch   400\n",
      "Epoch   17 batch   450\n",
      "[ 63.82465363] [63]\n",
      "Epoch   17 val.cost 0.000182 val.err 12.64% best\n",
      "Epoch   18 batch     0\n",
      "Epoch   18 batch    50\n",
      "Epoch   18 batch   100\n",
      "Epoch   18 batch   150\n",
      "Epoch   18 batch   200\n",
      "Epoch   18 batch   250\n",
      "Epoch   18 batch   300\n",
      "Epoch   18 batch   350\n",
      "Epoch   18 batch   400\n",
      "Epoch   18 batch   450\n",
      "[ 30.90010452] [9]\n",
      "Epoch   18 val.cost 0.000179 val.err 12.44% best\n",
      "Epoch   19 batch     0\n",
      "Epoch   19 batch    50\n",
      "Epoch   19 batch   100\n",
      "Epoch   19 batch   150\n",
      "Epoch   19 batch   200\n",
      "Epoch   19 batch   250\n",
      "Epoch   19 batch   300\n",
      "Epoch   19 batch   350\n",
      "Epoch   19 batch   400\n",
      "Epoch   19 batch   450\n",
      "[ 57.25611496] [57]\n",
      "Epoch   19 val.cost 0.000177 val.err 12.28% best\n",
      "Epoch   20 batch     0\n",
      "Epoch   20 batch    50\n",
      "Epoch   20 batch   100\n",
      "Epoch   20 batch   150\n",
      "Epoch   20 batch   200\n",
      "Epoch   20 batch   250\n",
      "Epoch   20 batch   300\n",
      "Epoch   20 batch   350\n",
      "Epoch   20 batch   400\n",
      "Epoch   20 batch   450\n",
      "[ 17.03642654] [17]\n",
      "Epoch   20 val.cost 0.000175 val.err 12.12% best\n",
      "Epoch   21 batch     0\n",
      "Epoch   21 batch    50\n",
      "Epoch   21 batch   100\n",
      "Epoch   21 batch   150\n",
      "Epoch   21 batch   200\n",
      "Epoch   21 batch   250\n",
      "Epoch   21 batch   300\n",
      "Epoch   21 batch   350\n",
      "Epoch   21 batch   400\n",
      "Epoch   21 batch   450\n",
      "[ 73.43688202] [74]\n",
      "Epoch   21 val.cost 0.000173 val.err 11.94% best\n",
      "Epoch   22 batch     0\n",
      "Epoch   22 batch    50\n",
      "Epoch   22 batch   100\n",
      "Epoch   22 batch   150\n",
      "Epoch   22 batch   200\n",
      "Epoch   22 batch   250\n",
      "Epoch   22 batch   300\n",
      "Epoch   22 batch   350\n",
      "Epoch   22 batch   400\n",
      "Epoch   22 batch   450\n",
      "[ 26.18570137] [2]\n",
      "Epoch   22 val.cost 0.000173 val.err 11.82% best\n",
      "Epoch   23 batch     0\n",
      "Epoch   23 batch    50\n",
      "Epoch   23 batch   100\n",
      "Epoch   23 batch   150\n",
      "Epoch   23 batch   200\n",
      "Epoch   23 batch   250\n",
      "Epoch   23 batch   300\n",
      "Epoch   23 batch   350\n",
      "Epoch   23 batch   400\n",
      "Epoch   23 batch   450\n",
      "[ 60.03240967] [59]\n",
      "Epoch   23 val.cost 0.000172 val.err 11.75% best\n",
      "Epoch   24 batch     0\n",
      "Epoch   24 batch    50\n",
      "Epoch   24 batch   100\n",
      "Epoch   24 batch   150\n",
      "Epoch   24 batch   200\n",
      "Epoch   24 batch   250\n",
      "Epoch   24 batch   300\n",
      "Epoch   24 batch   350\n",
      "Epoch   24 batch   400\n",
      "Epoch   24 batch   450\n",
      "[ 50.05317688] [49]\n",
      "Epoch   24 val.cost 0.000171 val.err 11.67% best\n",
      "Epoch   25 batch     0\n",
      "Epoch   25 batch    50\n",
      "Epoch   25 batch   100\n",
      "Epoch   25 batch   150\n",
      "Epoch   25 batch   200\n",
      "Epoch   25 batch   250\n",
      "Epoch   25 batch   300\n",
      "Epoch   25 batch   350\n",
      "Epoch   25 batch   400\n",
      "Epoch   25 batch   450\n",
      "[ 62.80694199] [62]\n",
      "Epoch   25 val.cost 0.000171 val.err 11.60% best\n",
      "Epoch   26 batch     0\n",
      "Epoch   26 batch    50\n",
      "Epoch   26 batch   100\n",
      "Epoch   26 batch   150\n",
      "Epoch   26 batch   200\n",
      "Epoch   26 batch   250\n",
      "Epoch   26 batch   300\n",
      "Epoch   26 batch   350\n",
      "Epoch   26 batch   400\n",
      "Epoch   26 batch   450\n",
      "[ 64.65650177] [62]\n",
      "Epoch   26 val.cost 0.000170 val.err 11.56% best\n",
      "Epoch   27 batch     0\n",
      "Epoch   27 batch    50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   27 batch   100\n",
      "Epoch   27 batch   150\n",
      "Epoch   27 batch   200\n",
      "Epoch   27 batch   250\n",
      "Epoch   27 batch   300\n",
      "Epoch   27 batch   350\n",
      "Epoch   27 batch   400\n",
      "Epoch   27 batch   450\n",
      "[ 45.41850281] [43]\n",
      "Epoch   27 val.cost 0.000170 val.err 11.53% best\n",
      "Epoch   28 batch     0\n",
      "Epoch   28 batch    50\n",
      "Epoch   28 batch   100\n",
      "Epoch   28 batch   150\n",
      "Epoch   28 batch   200\n",
      "Epoch   28 batch   250\n",
      "Epoch   28 batch   300\n",
      "Epoch   28 batch   350\n",
      "Epoch   28 batch   400\n",
      "Epoch   28 batch   450\n",
      "[ 41.8649292] [42]\n",
      "Epoch   28 val.cost 0.000170 val.err 11.49% best\n",
      "Epoch   29 batch     0\n",
      "Epoch   29 batch    50\n",
      "Epoch   29 batch   100\n",
      "Epoch   29 batch   150\n",
      "Epoch   29 batch   200\n",
      "Epoch   29 batch   250\n",
      "Epoch   29 batch   300\n",
      "Epoch   29 batch   350\n",
      "Epoch   29 batch   400\n",
      "Epoch   29 batch   450\n",
      "[ 55.21756744] [56]\n",
      "Epoch   29 val.cost 0.000169 val.err 11.46% best\n",
      "Epoch   30 batch     0\n",
      "Epoch   30 batch    50\n",
      "Epoch   30 batch   100\n",
      "Epoch   30 batch   150\n",
      "Epoch   30 batch   200\n",
      "Epoch   30 batch   250\n",
      "Epoch   30 batch   300\n",
      "Epoch   30 batch   350\n",
      "Epoch   30 batch   400\n",
      "Epoch   30 batch   450\n",
      "[ 21.54385757] [13]\n",
      "Epoch   30 val.cost 0.000168 val.err 11.45% best\n",
      "Epoch   31 batch     0\n",
      "Epoch   31 batch    50\n",
      "Epoch   31 batch   100\n",
      "Epoch   31 batch   150\n",
      "Epoch   31 batch   200\n",
      "Epoch   31 batch   250\n",
      "Epoch   31 batch   300\n",
      "Epoch   31 batch   350\n",
      "Epoch   31 batch   400\n",
      "Epoch   31 batch   450\n",
      "[ 22.91604233] [22]\n",
      "Epoch   31 val.cost 0.000168 val.err 11.44% best\n",
      "Epoch   32 batch     0\n",
      "Epoch   32 batch    50\n",
      "Epoch   32 batch   100\n",
      "Epoch   32 batch   150\n",
      "Epoch   32 batch   200\n",
      "Epoch   32 batch   250\n",
      "Epoch   32 batch   300\n",
      "Epoch   32 batch   350\n",
      "Epoch   32 batch   400\n",
      "Epoch   32 batch   450\n",
      "[ 32.88025665] [11]\n",
      "Epoch   32 val.cost 0.000168 val.err 11.41% best\n",
      "Epoch   33 batch     0\n",
      "Epoch   33 batch    50\n",
      "Epoch   33 batch   100\n",
      "Epoch   33 batch   150\n",
      "Epoch   33 batch   200\n",
      "Epoch   33 batch   250\n",
      "Epoch   33 batch   300\n",
      "Epoch   33 batch   350\n",
      "Epoch   33 batch   400\n",
      "Epoch   33 batch   450\n",
      "[ 81.22433472] [80]\n",
      "Epoch   33 val.cost 0.000168 val.err 11.43% stopping   1\n",
      "Epoch   34 batch     0\n",
      "Epoch   34 batch    50\n",
      "Epoch   34 batch   100\n",
      "Epoch   34 batch   150\n",
      "Epoch   34 batch   200\n",
      "Epoch   34 batch   250\n",
      "Epoch   34 batch   300\n",
      "Epoch   34 batch   350\n",
      "Epoch   34 batch   400\n",
      "Epoch   34 batch   450\n",
      "[ 25.69256592] [44]\n",
      "Epoch   34 val.cost 0.000168 val.err 11.44% stopping   2\n",
      "Epoch   35 batch     0\n",
      "Epoch   35 batch    50\n",
      "Epoch   35 batch   100\n",
      "Epoch   35 batch   150\n",
      "Epoch   35 batch   200\n",
      "Epoch   35 batch   250\n",
      "Epoch   35 batch   300\n",
      "Epoch   35 batch   350\n",
      "Epoch   35 batch   400\n",
      "Epoch   35 batch   450\n",
      "[ 25.49772263] [26]\n",
      "Epoch   35 val.cost 0.000168 val.err 11.39% best\n",
      "Epoch   36 batch     0\n",
      "Epoch   36 batch    50\n",
      "Epoch   36 batch   100\n",
      "Epoch   36 batch   150\n",
      "Epoch   36 batch   200\n",
      "Epoch   36 batch   250\n",
      "Epoch   36 batch   300\n",
      "Epoch   36 batch   350\n",
      "Epoch   36 batch   400\n",
      "Epoch   36 batch   450\n",
      "[ 48.80412674] [49]\n",
      "Epoch   36 val.cost 0.000168 val.err 11.42% stopping   1\n",
      "Epoch   37 batch     0\n",
      "Epoch   37 batch    50\n",
      "Epoch   37 batch   100\n",
      "Epoch   37 batch   150\n",
      "Epoch   37 batch   200\n",
      "Epoch   37 batch   250\n",
      "Epoch   37 batch   300\n",
      "Epoch   37 batch   350\n",
      "Epoch   37 batch   400\n",
      "Epoch   37 batch   450\n",
      "[ 26.17640877] [49]\n",
      "Epoch   37 val.cost 0.000168 val.err 11.40% stopping   2\n",
      "Epoch   38 batch     0\n",
      "Epoch   38 batch    50\n",
      "Epoch   38 batch   100\n",
      "Epoch   38 batch   150\n",
      "Epoch   38 batch   200\n",
      "Epoch   38 batch   250\n",
      "Epoch   38 batch   300\n",
      "Epoch   38 batch   350\n",
      "Epoch   38 batch   400\n",
      "Epoch   38 batch   450\n",
      "[ 36.56178284] [12]\n",
      "Epoch   38 val.cost 0.000168 val.err 11.43% stopping   3\n",
      "Epoch   39 batch     0\n",
      "Epoch   39 batch    50\n",
      "Epoch   39 batch   100\n",
      "Epoch   39 batch   150\n",
      "Epoch   39 batch   200\n",
      "Epoch   39 batch   250\n",
      "Epoch   39 batch   300\n",
      "Epoch   39 batch   350\n",
      "Epoch   39 batch   400\n",
      "Epoch   39 batch   450\n",
      "[ 87.07320404] [91]\n",
      "Epoch   39 val.cost 0.000168 val.err 11.42% stopping   4\n",
      "Epoch   40 batch     0\n",
      "Epoch   40 batch    50\n",
      "Epoch   40 batch   100\n",
      "Epoch   40 batch   150\n",
      "Epoch   40 batch   200\n",
      "Epoch   40 batch   250\n",
      "Epoch   40 batch   300\n",
      "Epoch   40 batch   350\n",
      "Epoch   40 batch   400\n",
      "Epoch   40 batch   450\n",
      "[ 30.65409279] [55]\n",
      "Epoch   40 val.cost 0.000169 val.err 11.46% stopping   5\n",
      "Epoch   41 batch     0\n",
      "Epoch   41 batch    50\n",
      "Epoch   41 batch   100\n",
      "Epoch   41 batch   150\n",
      "Epoch   41 batch   200\n",
      "Epoch   41 batch   250\n",
      "Epoch   41 batch   300\n",
      "Epoch   41 batch   350\n",
      "Epoch   41 batch   400\n",
      "Epoch   41 batch   450\n",
      "[ 5.94176435] [7]\n",
      "Epoch   41 val.cost 0.000169 val.err 11.47% stopping   6\n",
      "Epoch   42 batch     0\n",
      "Epoch   42 batch    50\n",
      "Epoch   42 batch   100\n",
      "Epoch   42 batch   150\n",
      "Epoch   42 batch   200\n",
      "Epoch   42 batch   250\n",
      "Epoch   42 batch   300\n",
      "Epoch   42 batch   350\n",
      "Epoch   42 batch   400\n",
      "Epoch   42 batch   450\n",
      "[ 49.94107437] [51]\n",
      "Epoch   42 val.cost 0.000169 val.err 11.47% stopping   7\n",
      "Epoch   43 batch     0\n",
      "Epoch   43 batch    50\n",
      "Epoch   43 batch   100\n",
      "Epoch   43 batch   150\n",
      "Epoch   43 batch   200\n",
      "Epoch   43 batch   250\n",
      "Epoch   43 batch   300\n",
      "Epoch   43 batch   350\n",
      "Epoch   43 batch   400\n",
      "Epoch   43 batch   450\n",
      "[ 51.67163849] [51]\n",
      "Epoch   43 val.cost 0.000169 val.err 11.55% stopping   8\n",
      "Epoch   44 batch     0\n",
      "Epoch   44 batch    50\n",
      "Epoch   44 batch   100\n",
      "Epoch   44 batch   150\n",
      "Epoch   44 batch   200\n",
      "Epoch   44 batch   250\n",
      "Epoch   44 batch   300\n",
      "Epoch   44 batch   350\n",
      "Epoch   44 batch   400\n",
      "Epoch   44 batch   450\n",
      "[ 54.32033157] [57]\n",
      "Epoch   44 val.cost 0.000169 val.err 11.60% stopping   9\n",
      "Epoch   45 batch     0\n",
      "Epoch   45 batch    50\n",
      "Epoch   45 batch   100\n",
      "Epoch   45 batch   150\n",
      "Epoch   45 batch   200\n",
      "Epoch   45 batch   250\n",
      "Epoch   45 batch   300\n",
      "Epoch   45 batch   350\n",
      "Epoch   45 batch   400\n",
      "Epoch   45 batch   450\n",
      "[ 48.89471054] [49]\n",
      "Epoch   45 val.cost 0.000169 val.err 11.58% stopping  10\n",
      "Early stopping triggered: Step:      22635, val.err 11.58%\n",
      "best model saved to: ./best_model/model_20180608_010508\n",
      "Total time: 1948.757489\n",
      "INFO:tensorflow:Restoring parameters from ./best_model/model_20180608_010508\n",
      "Test Err: 12.23%\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'./final_model/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "dnn(df_X, df_Y, df2_X, df2_y, df3_X, df3_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
